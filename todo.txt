## 1. Add batch inference for llama-based models.
## 2. Add multi tasks inference to avoid the time of loading foundation models.
## 3. saving the prompt in experiment runs
