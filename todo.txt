## 1. Add batch inference for llama-based models.
## 2. Add multi tasks inference to avoid the time of loading foundation models.
